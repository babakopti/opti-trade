\documentclass{article}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{natbib}
\renewcommand{\refname}{References}
\usepackage{url}

\title{A Differential Geometric Approach to Economic Forecast}

\author{Babak Emami}

\date{\today}

\begin{document}
\maketitle

\begin{abstract}


\end{abstract}

\section{Introduction}\label{section:introduction}

The usual approach to predicting price of an asset is to regress the
historical prices of tat asset against a set of economic
indicators. The problem with this approach is that we still need
knowldege of the future values of economic indicators. This is done by
relying on estimate forecasts of econimic indicators which are often
based on qualitative methods, such as those in Blue Chip Economic
Indicators and Blue Chip Financial Forecasts~\cite{ref:blue-chip}. The
forecasts in Blue Chip publications are based on surveying top
business economists in the United States.

An approach is proposed to forecast economic variables without
depending on future values of any economic indicators. We look at the
economy as a multi-demensional manifold; each dimension is an economic
variable. These variables can be marco-economic indicators or asset
prices. We refer to this manifold as an economic universe. The
observed values of economic variables in a time period form a path in
this universe. We refer to this path as the economic path. We then
find a manifold for which this path is a geodesic, governed by a
system of differential equations. The fututre value of economc
variables can be predicted by solving this system of differential
equations.

In what follows the mathematical framework used is discussed and a
methodology is proposed to infer the structure of economic universe
given a set of observed economic variables. Some results are presented
followed by a model parameter study. Finally, a trading algorithm is
proposed using this approach to forecast asset prices.

\section{Mathematical Framework}\label{section:mathematical-framework}

Let us consider $n$ variables $x^{1}$ to $x^{n}$ that are smooth
functions of time $t$; $x^{i} = x^{i}(t)$. Moreover, let us consider a
smooth real manifold $M$ equipped with $(x^{1},x^{2},...,x^{n})$ as a
coordinate system. Each set of coordinate values
$(x^{1}(t),...,x^{n}(t))$ denotes a point $p$ on $M$. Values of these
$n$ variables over a period of time $[0,T]$ form a path over $M$. This
path is smooth as $x^{i}$s are smooth functions of time. Now let us
add a constraint on $M$ by assuming that the path formed by
$x^{i}(t)$s is a geodesic of $M$. With this assumption, this path is
governed by the follwoing system of ordinary differential equations,

\begin{equation}\label{eqn:geodesic}
\ddot{x}^{m} + \Gamma^{m}_{ab} \dot{x}^{a} \dot{x}^{b} = 0
\end{equation}

The Christoffel symbols $Gamma^{m}_{ab}$ are in general functions of
coordinates. In the current work, we assume that Christoffel symbols
are constant. This is a sufficient (but not necessary) condition for
the manifold to have a constant curvature. This assumption is rather
strong and as such we should revisit this subject.

To further simplify the problem, we assume that variables of interest
are in fact $y^{m} = \frac{dx^{m}}{dt}$. This will allow us to work
with a set of first order ODEs,

\begin{equation}\label{eqn:geodesic-1st-order}
\dot{y}^{m} + \Gamma^{m}_{ab} y^{a} y^{b} = 0
\end{equation}

The above system of ODEs needs a boundary condition,

\begin{equation}\label{eqn:geodesic-bc}
\dot{y}^{m}(t_{BC}) = \dot{y}^{m}_{0}
\end{equation}

where $m,a,b \in [1,n] \cap \mathbb{N}$, and $t_{BC}$ is the time at
which a boundary condition is set. For now, we choose $t_{BC} = T$ to
emphasize on the more recent data in training. One can potentially
define a more complex boundary condition that accounts for some
attenuation from recent to older data. We shall revisit this in
future.

This means that the variables of interest are elements of the tangent
bundle of manifold $M$, that is $y^{m}(T) \in T_{p(t)}M$, where $p(t) \in M$
corresponds to coordinates $(x^{1}(t),x^{2}(t),...,x^{n}(t))$.

Now, let us further assume that the values of variables $y^{m}(t)$ are
known for $t \in [0,T]$. Using this a set of training data, we can
determine $Gamma^{m}_{ab}$ by fitting Eq.~\ref{eqn:geodesic-1st-order}
over the training data. This can be done using a continuous adjoint
approach~\cite{ref:adjoint-giles}.

The adjoint approach is used to solve a minimization problem
constrained by a system of differential equations. Here, we want to
solve the follwoing constrained optimization problem,

\begin{equation}\label{eqn:optimization-problem}
\min_{\Gamma^{m}_{ab}} J(\vec{y},\Gamma^{m}_{ab})
\end{equation}

where the objective function $J$ is defined as,

\begin{equation}\label{eqn:optimization-objective-raw}
J(\vec{y},\Gamma^{m}_{ab}) = \int_{0}^{T} \frac{1}{2} \eta(t) \left\Vert
\vec{y}(t) - \hat{\vec{y}}(t) \right\Vert^{2} dt
\end{equation}

subject to the system of ODEs in Eq.~\ref{eqn:geodesic-1st-order} with
boundary condition of Eq.~\ref{eqn:geodesic-bc} as a constraint, where
$\vec{y}$ represents a vector with $y^{i}$ as its elements,
$\hat{\vec{y}}$ is the observed value of $\vec{y}$, and $\left\Vert
\right\Vert$ is the L2 norm. Also, $\eta(t)$ is a function of time
which allows to introduce a weight in th eobjective function. This
weight can be used to emphasize on the more recent training data. For
instance when treating the problem numerically, we can define $\eta(t)
= \eta_{0} + \frac{1.0 - \eta_{0}}{T} t$ where $\eta_{0} \in (0,1]$ is
  an attenuation parameter.

The ODE constraint can be added using continuous Lagrangian multiplier
$\vec{v}$. The objective functiomn

\begin{equation}\label{eqn:optimization-objective}
J(\vec{y},\Gamma^{m}_{ab}) = \int_{0}^{T} \frac{1}{2} \eta(t)
\left\Vert \vec{y}(t) - \hat{\vec{y}}(t) \right\Vert^{2} dt +
\int_{0}^{T} \vec{v} \dot ( \dot{y}^{m} + \Gamma^{m}_{ab} y^{a} y^{b}
) + \frac{1}{2} \zeta \left\Vert \Gamma^{m}_{ab} \right\Vert^{2}
\end{equation}

where the last term introduces a quadratic regularization, and $\zeta$
is a constant regularization coefficient. Note too that the continuous
Lagrangian multiplier $\vec{v}$ is a cotangent vector with elements
$v_{1}$, $v_{2}$,..., $v_{n}$.

\section{Results and Discussion}\label{section:results-discussion}

\subsection{Results of a Sample Manifold}\label{subsection:some-results}

A 33-dimensional manifold is built using the above-mentioned
approach. The dimensions of the manifold correspond to prices of the
following ETFs (exchanged-traded funds),

\begin{itemize}
    \item[] QQQ: PowerShares QQQ 
    \item[] SPY: SPDR S\&P 500 Growth ETF 
    \item[] DIA: SPDR Dow Jones Industrial Average ETF 
    \item[] MDY: SPDR S\&P MidCap 400 ETF 
    \item[] IWM: iShares Russell 2000 Index Fund 
    \item[] OIH: Market Vectors Oil Services ETF 
    \item[] SMH: Market Vectors Semiconductor ETF 
    \item[] XLE: Energy Select Sector SPDR Fund 
    \item[] XLF: Financial Select Sector SPDR Fund 
    \item[] XLU: Utilities Select Sector SPDR Fund 
    \item[] EWJ: iShares MSCI Japan Index Fund
\end{itemize}

prices of the following (continuous) futures contracts,

\begin{itemize}
    \item[] ES:  E-mini S\&P 500 Continuous Contract 
    \item[] NQ:  E-mini Nasdaq 100 Continuous Contract 
    \item[] YM:  E-mini Dow Futures Continuous Contract 
    \item[] RTY: E-mini Russell 2000 Continuous Contract 
    \item[] EMD: E-mini S\&P MidCap 400 Continuous Contract 
    \item[] QM:  E-mini Crude Oil Futures Continuous Contract 
    \item[] US:  30 Year U.S. Treasury Bonds Continuous Contract    
\end{itemize}

and values of the following financial indices,

\begin{itemize}
    \item[] INDU:  Dow Jones Industrial Average 
    \item[] NDX:   Nasdaq 100 Index 
    \item[] SPX:   S\&P 500 Index 
    \item[] COMPX: Nasdaq Composite Index 
    \item[] RUT:   Russell 2000 Index 
    \item[] OEX:   S\&P 100 Index 
    \item[] MID:   S\&P 400 Midcap Index 
    \item[] SOX:   PHLX Semiconductor Sector Index 
    \item[] RUI:   Russell 1000 Index 
    \item[] RUA:   Russell 3000 Index 
    \item[] TRAN:  Dow Jones Transportation Average 
    \item[] HGX:   PHLX Housing Sector Index 
    \item[] TYX:   30-Year Treasury Bond 
    \item[] HUI:   NYSE Arca Gold BUGS Index 
    \item[] XAU:   PHLX Gold/Silver Sector Index
\end{itemize}

Here we assume that the above variables are elements of the tanget
bundle of our manifold, that is $y^{m}(t)$ in
Eq.~\ref{eqn:geodesic-1st-order}. In other words, coordinates of our
manifold, $x^{m}(t)$ in Eq.~\ref{eqn:geodesic}, are cumulative of the
above variables.

We trained this maniofold using intraday minute-based data spanning
2017-01-03 to 2018-01-03. The model is tested on three days of
out-of-sample data corresponding to the first three business days
after training period. Figure~\ref{fig:results-spy} shows in-sample
and out-of-sample forecast results for SPY as a function of time in
minutes; figure~\ref{fig:results-spy-oos} is zoomed on the
out-of-sample forecast. The out of sample results are reasonable. The
average relative error of out-of-sample forecasts of all variables in
the model is 3.5\%.

\begin{figure}\label{fig:results-spy}
\includegraphics[scale=0.5,bb=0 0 320 240]{figures/results-SPY.png}
\caption{In-sample and out-of-sample forecast results for SPY.}
\end{figure}

\begin{figure}\label{fig:results-spy-oos}
\includegraphics[bb=0 0 640 480]{figures/results-SPY-oos.png}
\caption{Out-of-sample forecast results for SPY.}
\end{figure}

\subsection{A Model Parameter Study}\label{subsection:model-parameter-study}

A model parameter study is performed for the following parameters,

\begin{itemize}

    \item Tolerance used for norm of gradient of objective function in
      numerical solution of optimization problem in
      Eq.~\ref{eqn:optimization-objective}.
  
    \item Training period, that is $T$ in
      Eq.~\ref{eqn:optimization-objective}.
  
    \item Regularization coefficient, that is $\zeta$ in
      Eq.~\ref{eqn:optimization-objective}.

    \item Attenuation parameter $\eta_{0}$.
      
\end{itemize}

Manifold models are built using the variables discussed in
section~\ref{subsection:some-results}.

Figure~\ref{fig:tolerance-sensitivity-error} shows the in-sample
relative error vs. optimization tolerance, where the in-sample
relative error, $E$ is defined as,

\begin{equation}\label{eqn:in-sample-error}
E = \frac{\int_{0}^{T} \eta(t) \left\Vert \vec{y}(t) -
  \hat{\vec{y}}(t) \right\Vert^{2} dt}{\int_{0}^{T} \eta(t) \left\Vert
  \hat{\vec{y}}(t) \right\Vert^{2} dt}
\end{equation}

\begin{figure}\label{fig:tolerance-sensitivity-error}
\includegraphics[bb=0 0 640 480]{figures/tolerance-sensitivity-error.png}
\caption{In-sample relative error vs. optimization tolerance; $T$ =
  360 days, $\eta(t) = 1.0$, $\zeta$ = 1.0e-3.}
\end{figure}

As expected, the in-sample error reduces as a tighter optimization
tolerance is used.

To evaluate the out-of-sample performance of the forecast model, we
define an out-of-sample period $(T,T+T^{oos}]$, and an out-of-sample
  error $E^{oos}$, defined as,

\begin{equation}\label{eqn:out-of-sample-error}
E^{oos} = \frac{\int_{T}^{T+T^{oos}} \eta(t) \left\Vert \vec{y}(t) -
  \hat{\vec{y}}(t) \right\Vert^{2} dt}{\int_{T}^{T+T^{oos}} \eta(t)
  \left\Vert \hat{\vec{y}}(t) \right\Vert^{2} dt}
\end{equation}

Figure~\ref{fig:tolerance-sensitivity-oos-error} shows out-of-sample
error vs. optimization tolerance. As can be seen, the behavior of
out-of-sample error is consistent with that of in-sample and decreases
when the tolerance is made tighter.

\begin{figure}\label{fig:tolerance-sensitivity-oos-error}
\includegraphics[bb=0 0 640 480]{figures/tolerance-sensitivity-oos-error.png}
\caption{Out-of-sample relative error vs. optimization tolerance; $T$
  = 360 days, $T^{oos}$ = 3, days$\eta(t)$ = 1.0, $\zeta$ = 1.0e-3.}
\end{figure}

Figure~\ref{fig:nTrnDays-sensitivity-oos-error} show the out-of-sample
error vs. number of days, $T$, used for model training. As can be
seen, the out-of-sample performance improves when a longer training
period is used, while the improvement begins to plateau around a
training period of two years. 

\begin{figure}\label{fig:nTrnDays-sensitivity-oos-error}
\includegraphics[bb=0 0 640 480]{figures/nTrnDays-sensitivity-oos-error.png}
\caption{Out-of-sample relative error vs. number of days used for
  training; $T^{oos}$ = 3, $\eta(t)$ = 1.0, $\zeta$ = 1.0e-3,
  tolerance = 0.05.}
\end{figure}

It is worth mentioning that the in-sample error did not show any
correlation to the length of training period as can be seen in
Figure~\ref{fig:nTrnDays-sensitivity-error}.

\begin{figure}\label{fig:nTrnDays-sensitivity-error}
\includegraphics[bb=0 0 640 480]{figures/nTrnDays-sensitivity-error.png}
\caption{In-sample relative error vs. number of days used for
  training; $\eta(t) = 1.0$, $\zeta$ = 1.0e-3, tolerance = 0.05.}
\end{figure}

Turning to regularization, Figure~\ref{fig:regCoef-sensitivity-error}
shows that using a regularization coefficient, $\zeta$, of up to
around 1.0e-3 does not introduce a significant in-sample error. The
in-sample error, however, increases as regularization coefficient
grows beyond 1.0e-3.

\begin{figure}\label{fig:regCoef-sensitivity-error}
\includegraphics[bb=0 0 640 480]{figures/regCoef-sensitivity-error.png}
\caption{In-sample relative error vs. regularization coefficient; $T$
  = 360 days, $\eta(t)$ = 1.0, tolerance = 0.05.}
\end{figure}

The out-of-sample error shows a similar relationship to regularization
coefficient, as shown in
Figure~\ref{fig:regCoef-sensitivity-oos-error}.

\begin{figure}\label{fig:regCoef-sensitivity-oos-error}
\includegraphics[bb=0 0 640 480]{figures/regCoef-sensitivity-oos-error.png}
\caption{Out-of-sample relative error vs. regularization coefficient;
  $T$ = 360 days, $T^{oos}$ = 3, $\eta(t)$ = 1.0, tolerance = 0.05.}
\end{figure}

Finally, we studied the effect of the attenuation parameter,
$\eta_{0}$. Note that the attenuatuation function is defined as
$\eta(t) = \eta_{0} + \frac{1.0 - \eta_{0}}{T} t$. This means that
$\eta_{0}$ = 1.0 corresponds to no attenuation, whereas $\eta_{0}$ = 0
yields the maximum attenuation using the above-mentioned attenuation
function. Figure~\ref{fig:atnFct-sensitivity-error} show the in-sample
error vs. attenuation parameter $\eta_{0}$. The in-sample error
decreases as more attenuation is introduced. This is expected as we
apply a boundary condition at $t = T$, so the in-sample results
already tend to better match the recent actuals. Inroducing
attenuation lowers weight of the less recent data and as such reduces
the overall in-sample error.

\begin{figure}\label{fig:atnFct-sensitivity-error}
\includegraphics[bb=0 0 640 480]{figures/atnFct-sensitivity-error.png}
\caption{In-sample relative error vs. attenuation parameter; $T$ = 360
  days, $\zeta$ = 1.0e-3, tolerance = 0.05.}
\end{figure}

The out-of-sample error, on the other hand, does not show any obvious
relationship to attenuation as seen in
Figure~\ref{fig:atnFct-sensitivity-oos-error}.

\begin{figure}\label{fig:atnFct-sensitivity-oos-error}
\includegraphics[bb=0 0 640 480]{figures/atnFct-sensitivity-oos-error.png}
\caption{Out-of-sample relative error vs. attenuation parameter; $T$ =
  360 days, $T^{oos}$ = 3, $\zeta$ = 1.0e-3, tolerance = 0.05.}
\end{figure}

\subsection{On Behavior of Christoffel Symbols}\label{subsection:christoffel-behavior}

Let us revist the assumption of a constant Christoffel symbol,
$\Gamma^{m}_{ab}$ briefly. To study this, a collection of manifold
models were built using training data of 360 days ending at each
business day of 2018. Each model uses a constant Christoffel symbol as
explained in
section~\ref{section:mathematical-framework}. Figure~\ref{fig:gamma-time}
shows the norm of christoffel symbol, $\left\Vert \Gamma^{m}_{ab}
\right\Vert$, vs. the last training day of each model. This shows the
behavior of Christoffel symbol; it is more more or less
periodic. These results can be useful when we move beyonf constant
Christoffel symbols in future work.

\begin{figure}\label{fig:gamma-time}
\includegraphics[bb=0 0 640 480]{figures/Gamma_time_2018.png}
\caption{Norm of Gamma vs. snapdate Each point on the plot comes from
  a model with a constant Christoffel symbol; for all models we have
  $T$ = 360 days, $\zeta$ = 1.0e-3, $\eta_{0}$ = 1.0, tolerance =
  0.05.}
\end{figure}

\section{A Proposed Trading Algorithm}\label{section:trading-algorithm}


\bibliography{references}
\bibliographystyle{plain}

\end{document}

